from google.cloud import vision
from langchain_core.tools import tool
from typing import Optional, List, Dict, Any
import os
import logging
from pathlib import Path

logger = logging.getLogger(__name__)

# Global variable to store current uploaded files from LangGraph state
_CURRENT_UPLOADED_FILES = []

def set_current_uploaded_files(files: List[str]):
    """Set the current uploaded files from LangGraph state."""
    global _CURRENT_UPLOADED_FILES
    _CURRENT_UPLOADED_FILES = files
    logger.info(f"ğŸ”§ Vision tools: Updated current files from state: {len(files)} files")

def _resolve_file_path_from_state(file_path: str, uploaded_files: List[str] = None) -> str:
    """
    Resolve a file path by checking if it exists directly, or if it's just a filename,
    try to find it in the uploaded files list from LangGraph state.
    """
    logger.info(f"ğŸ” Vision tool resolving file path: '{file_path}'")
    
    # If the path exists directly, return it
    if os.path.exists(file_path):
        logger.info(f"âœ… File found directly at: {file_path}")
        return file_path
    
    # Use provided uploaded_files or fall back to global current files
    files_to_check = uploaded_files or _CURRENT_UPLOADED_FILES
    
    # If it's just a filename, try to find it in uploaded files from state
    if files_to_check:
        logger.info(f"ğŸ“ Checking uploaded files from state: {files_to_check}")
        filename = os.path.basename(file_path)
        logger.info(f"ğŸ” Looking for filename: '{filename}'")
        
        for uploaded_path in files_to_check:
            uploaded_filename = os.path.basename(uploaded_path)
            logger.info(f"ğŸ“„ Comparing with uploaded file: '{uploaded_filename}' (full path: {uploaded_path})")
            
            if uploaded_filename == filename:
                if os.path.exists(uploaded_path):
                    logger.info(f"âœ… Found matching file: {uploaded_path}")
                    return uploaded_path
                else:
                    logger.warning(f"âš ï¸ Matching filename found but file doesn't exist: {uploaded_path}")
    else:
        logger.warning("âš ï¸ No uploaded files available from state")
    
    # File not found
    logger.warning(f"âŒ File not found: {file_path}")
    return None

def init_vision_client():
    """
    Initialize the Google Cloud Vision API client.
    
    Returns:
        vision.ImageAnnotatorClient: The initialized Vision API client
        
    Raises:
        Exception: If client initialization fails
    """
    try:
        logger.info("ğŸ”§ Checking Google Cloud credentials...")
        # Check for credentials
        if not os.getenv('GOOGLE_APPLICATION_CREDENTIALS'):
            raise ValueError("GOOGLE_APPLICATION_CREDENTIALS environment variable is required")
        
        creds_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')
        logger.info(f"ğŸ“‹ Using credentials: {creds_path}")
        
        if not os.path.exists(creds_path):
            raise ValueError(f"Credentials file not found: {creds_path}")
            
        logger.info("ğŸ”Œ Initializing Vision API client...")
        client = vision.ImageAnnotatorClient()
        logger.info("âœ… Google Cloud Vision API client initialized successfully")
        return client
    except Exception as e:
        logger.error(f"âŒ Failed to initialize Vision API client: {e}")
        raise

@tool
def vision_diagnostic_tool() -> str:
    """
    Diagnostic tool to check Google Cloud Vision API configuration and connectivity.
    
    This tool helps diagnose issues with Google Cloud Vision API setup including
    credentials, project configuration, and API access.
    
    Returns:
        Diagnostic information about the Vision API setup
    """
    logger.info("ğŸ”§ Starting Vision API diagnostics...")
    
    results = []
    results.append("ğŸ”§ GOOGLE CLOUD VISION API DIAGNOSTICS")
    results.append("=" * 50)
    
    # Check environment variables
    results.append("\nğŸ“‹ ENVIRONMENT VARIABLES:")
    
    google_creds = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')
    if google_creds:
        results.append(f"âœ… GOOGLE_APPLICATION_CREDENTIALS: {google_creds}")
        logger.info(f"ğŸ“‹ Found credentials path: {google_creds}")
        # Check if file exists
        if os.path.exists(google_creds):
            file_size = os.path.getsize(google_creds)
            results.append(f"âœ… Credentials file exists: {file_size} bytes")
            logger.info(f"âœ… Credentials file verified: {file_size} bytes")
        else:
            results.append(f"âŒ Credentials file not found: {google_creds}")
            logger.error(f"âŒ Credentials file missing: {google_creds}")
    else:
        results.append("âŒ GOOGLE_APPLICATION_CREDENTIALS: Not set")
        logger.error("âŒ GOOGLE_APPLICATION_CREDENTIALS not set")
    
    google_project = os.getenv('GOOGLE_PROJECT_ID') or os.getenv('GOOGLE_CLOUD_PROJECT')
    if google_project:
        results.append(f"âœ… GOOGLE_PROJECT_ID: {google_project}")
        logger.info(f"ğŸ“‹ Project ID: {google_project}")
    else:
        results.append("âš ï¸ GOOGLE_PROJECT_ID: Not set (optional)")
        logger.warning("âš ï¸ GOOGLE_PROJECT_ID not set")
    
    # Try to initialize client
    results.append("\nğŸ”Œ CLIENT INITIALIZATION:")
    try:
        logger.info("ğŸ”Œ Attempting to initialize Vision client...")
        client = init_vision_client()
        results.append("âœ… Vision API client initialized successfully")
        logger.info("âœ… Vision client initialization successful")
        
        # Try a simple API call (if we have credentials)
        try:
            logger.info("ğŸ§ª Testing API connectivity with sample image...")
            # Create a tiny test image (1x1 pixel PNG)
            test_image_data = b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x00\x01\x00\x00\x00\x01\x08\x06\x00\x00\x00\x1f\x15\xc4\x89\x00\x00\x00\nIDATx\x9cc\x00\x01\x00\x00\x05\x00\x01\r\n-\xdb\x00\x00\x00\x00IEND\xaeB`\x82'
            image = vision.Image(content=test_image_data)
            
            logger.info("ğŸ“ Making test API call...")
            response = client.label_detection(image=image)
            
            if response.error.message:
                results.append(f"âš ï¸ API test call returned error: {response.error.message}")
                logger.warning(f"âš ï¸ API error: {response.error.message}")
            else:
                results.append("âœ… API test call successful")
                logger.info("âœ… API test successful")
                
                # Log response details
                if response.label_annotations:
                    logger.info(f"ğŸ“Š Test returned {len(response.label_annotations)} labels")
                else:
                    logger.info("ğŸ“Š Test returned no labels (expected for 1px image)")
                
        except Exception as e:
            error_details = str(e)
            results.append(f"âš ï¸ API test call failed: {error_details}")
            logger.error(f"âŒ API test failed: {error_details}")
            
            # Log more specific error information
            if "403" in error_details:
                logger.error("ğŸ”’ HTTP 403: Vision API not enabled or insufficient permissions")
            elif "429" in error_details:
                logger.error("â° HTTP 429: API quota exceeded")
            elif "401" in error_details:
                logger.error("ğŸ”‘ HTTP 401: Authentication failed")
            
    except Exception as e:
        error_details = str(e)
        results.append(f"âŒ Client initialization failed: {error_details}")
        logger.error(f"âŒ Client init failed: {error_details}")
    
    # Check available features
    results.append("\nğŸ¯ AVAILABLE FEATURES:")
    features = [
        "Label Detection", "Object Detection", "Face Detection", 
        "Landmark Detection", "Text Detection", "Web Detection", 
        "Safe Search Detection", "Document Text Detection"
    ]
    for feature in features:
        results.append(f"ğŸ“‹ {feature}: Available")
    
    # Check working directory and common image paths
    results.append("\nğŸ“ FILE SYSTEM:")
    results.append(f"ğŸ—‚ï¸ Current working directory: {os.getcwd()}")
    
    common_paths = [
        "C:\\Users\\Richard\\Downloads",
        "C:\\Users\\Richard\\Documents", 
        ".",
        "./uploads",
        "/tmp"
    ]
    
    for path in common_paths:
        if os.path.exists(path):
            results.append(f"âœ… Path exists: {path}")
        else:
            results.append(f"âŒ Path not found: {path}")
    
    logger.info("ğŸ‰ Vision API diagnostics completed")
    return "\n".join(results)

@tool
def vision_image_analysis_tool(
    image_path: str,
    analysis_features: Optional[List[str]] = None,
    uploaded_files: Optional[List[str]] = None
) -> str:
    """
    Comprehensive image analysis using Google Cloud Vision API.
    
    This tool provides complete image understanding including object detection,
    label detection, face detection, landmark detection, and more.
    
    Args:
        image_path: Path to the image file to analyze
        analysis_features: List of features to analyze ['labels', 'objects', 'faces', 'landmarks', 'text', 'web', 'safe_search']
        uploaded_files: List of uploaded file paths from LangGraph state
    
    Returns:
        Comprehensive image analysis results
    """
    logger.info(f"ğŸ–¼ï¸ Starting comprehensive image analysis for: {image_path}")
    
    try:
        logger.info("ğŸ”„ Initializing Google Cloud Vision client for comprehensive analysis...")
        client = init_vision_client()
        logger.info("âœ… Vision client ready for image analysis")
    except Exception as e:
        error_msg = f"âŒ Error: Failed to initialize Google Cloud Vision client: {str(e)}"
        logger.error(error_msg)
        return error_msg
    
    try:
        # Resolve file path first
        resolved_path = _resolve_file_path_from_state(image_path, uploaded_files)
        if not resolved_path:
            error_msg = f"âŒ Error: Image file not found: {image_path}"
            logger.error(error_msg)
            return error_msg
        
        logger.info(f"ğŸ“– Reading image file: {resolved_path}")
        # Read the image file
        with open(resolved_path, "rb") as image_file:
            content = image_file.read()
        
        logger.info(f"âœ… Image loaded successfully: {len(content):,} bytes")
        
        # Create image object
        image = vision.Image(content=content)
        
        # Default features if none specified
        if not analysis_features:
            analysis_features = ['labels', 'objects', 'text', 'faces']
        
        logger.info(f"ğŸ” Analysis features requested: {analysis_features}")
        
        results = []
        filename = os.path.basename(resolved_path)
        file_size = len(content)
        
        results.append(f"ğŸ–¼ï¸ Image: {filename}")
        results.append(f"ğŸ“ File size: {file_size:,} bytes")
        results.append(f"ğŸ” Analysis features: {', '.join(analysis_features)}")
        results.append("")
        
        # Label Detection
        if 'labels' in analysis_features:
            try:
                logger.info("ğŸ·ï¸ Performing label detection...")
                response = client.label_detection(image=image)
                logger.info("âœ… Label detection API call completed")
                
                if response.error.message:
                    error_msg = f"ğŸ·ï¸ LABELS: API Error - {response.error.message}"
                    results.append(error_msg)
                    logger.error(f"âŒ Label detection error: {response.error.message}")
                else:
                    labels = response.label_annotations
                    if labels:
                        results.append("ğŸ·ï¸ LABELS DETECTED:")
                        logger.info(f"ğŸ“Š Found {len(labels)} labels")
                        for label in labels[:10]:  # Top 10 labels
                            confidence = int(label.score * 100)
                            results.append(f"  â€¢ {label.description}: {confidence}% confidence")
                            logger.debug(f"ğŸ·ï¸ Label: {label.description} ({confidence}%)")
                    else:
                        results.append("ğŸ·ï¸ LABELS: None detected")
                        logger.info("ğŸ“Š No labels detected")
                results.append("")
            except Exception as e:
                error_msg = f"ğŸ·ï¸ LABELS: Error - {str(e)}"
                results.append(error_msg)
                logger.error(f"âŒ Label detection exception: {str(e)}")
                results.append("")
        
        # Object Detection
        if 'objects' in analysis_features:
            try:
                logger.info("ğŸ“¦ Performing object detection...")
                response = client.object_localization(image=image)
                logger.info("âœ… Object detection API call completed")
                
                if response.error.message:
                    error_msg = f"ğŸ“¦ OBJECTS: API Error - {response.error.message}"
                    results.append(error_msg)
                    logger.error(f"âŒ Object detection error: {response.error.message}")
                else:
                    objects = response.localized_object_annotations
                    if objects:
                        results.append("ğŸ“¦ OBJECTS DETECTED:")
                        logger.info(f"ğŸ“Š Found {len(objects)} objects")
                        for obj in objects[:5]:  # Top 5 objects
                            confidence = int(obj.score * 100)
                            results.append(f"  â€¢ {obj.name}: {confidence}% confidence")
                            logger.debug(f"ğŸ“¦ Object: {obj.name} ({confidence}%)")
                            # Add bounding box info
                            vertices = obj.bounding_poly.normalized_vertices
                            if vertices:
                                x1, y1 = vertices[0].x, vertices[0].y
                                x2, y2 = vertices[2].x, vertices[2].y
                                results.append(f"    Location: ({x1:.2f}, {y1:.2f}) to ({x2:.2f}, {y2:.2f})")
                    else:
                        results.append("ğŸ“¦ OBJECTS: None detected")
                        logger.info("ğŸ“Š No objects detected")
                results.append("")
            except Exception as e:
                error_msg = f"ğŸ“¦ OBJECTS: Error - {str(e)}"
                results.append(error_msg)
                logger.error(f"âŒ Object detection exception: {str(e)}")
                results.append("")
        
        # Face Detection
        if 'faces' in analysis_features:
            try:
                logger.info("ğŸ‘¤ Performing face detection...")
                response = client.face_detection(image=image)
                logger.info("âœ… Face detection API call completed")
                
                if response.error.message:
                    error_msg = f"ğŸ‘¤ FACES: API Error - {response.error.message}"
                    results.append(error_msg)
                    logger.error(f"âŒ Face detection error: {response.error.message}")
                else:
                    faces = response.face_annotations
                    if faces:
                        results.append(f"ğŸ‘¤ FACES DETECTED: {len(faces)} face(s)")
                        logger.info(f"ğŸ“Š Found {len(faces)} faces")
                        for i, face in enumerate(faces[:3]):  # Top 3 faces
                            results.append(f"  Face {i+1}:")
                            # Emotions
                            emotions = {
                                'Joy': face.joy_likelihood.name,
                                'Anger': face.anger_likelihood.name,
                                'Surprise': face.surprise_likelihood.name,
                                'Sorrow': face.sorrow_likelihood.name
                            }
                            results.append(f"    Emotions: {', '.join([f'{k}:{v}' for k,v in emotions.items() if v != 'UNKNOWN'])}")
                            
                            # Detection confidence
                            if face.detection_confidence:
                                conf = int(face.detection_confidence * 100)
                                results.append(f"    Confidence: {conf}%")
                    else:
                        results.append("ğŸ‘¤ FACES: None detected")
                        logger.info("ğŸ“Š No faces detected")
                results.append("")
            except Exception as e:
                error_msg = f"ğŸ‘¤ FACES: Error - {str(e)}"
                results.append(error_msg)
                logger.error(f"âŒ Face detection exception: {str(e)}")
                results.append("")
        
        # Landmark Detection
        if 'landmarks' in analysis_features:
            try:
                logger.info("ğŸ›ï¸ Performing landmark detection...")
                response = client.landmark_detection(image=image)
                logger.info("âœ… Landmark detection API call completed")
                
                if response.error.message:
                    error_msg = f"ğŸ›ï¸ LANDMARKS: API Error - {response.error.message}"
                    results.append(error_msg)
                    logger.error(f"âŒ Landmark detection error: {response.error.message}")
                else:
                    landmarks = response.landmark_annotations
                    if landmarks:
                        results.append("ğŸ›ï¸ LANDMARKS DETECTED:")
                        logger.info(f"ğŸ“Š Found {len(landmarks)} landmarks")
                        for landmark in landmarks[:3]:  # Top 3 landmarks
                            confidence = int(landmark.score * 100)
                            results.append(f"  â€¢ {landmark.description}: {confidence}% confidence")
                            logger.debug(f"ğŸ›ï¸ Landmark: {landmark.description} ({confidence}%)")
                            if landmark.locations:
                                lat = landmark.locations[0].lat_lng.latitude
                                lng = landmark.locations[0].lat_lng.longitude
                                results.append(f"    Location: {lat:.4f}, {lng:.4f}")
                    else:
                        results.append("ğŸ›ï¸ LANDMARKS: None detected")
                        logger.info("ğŸ“Š No landmarks detected")
                results.append("")
            except Exception as e:
                error_msg = f"ğŸ›ï¸ LANDMARKS: Error - {str(e)}"
                results.append(error_msg)
                logger.error(f"âŒ Landmark detection exception: {str(e)}")
                results.append("")
        
        # Text Detection
        if 'text' in analysis_features:
            try:
                logger.info("ğŸ“ Performing text detection...")
                response = client.text_detection(image=image)
                logger.info("âœ… Text detection API call completed")
                
                if response.error.message:
                    error_msg = f"ğŸ“ TEXT: API Error - {response.error.message}"
                    results.append(error_msg)
                    logger.error(f"âŒ Text detection error: {response.error.message}")
                else:
                    texts = response.text_annotations
                    if texts:
                        full_text = texts[0].description
                        text_preview = full_text[:100] + "..." if len(full_text) > 100 else full_text
                        results.append(f"ğŸ“ TEXT DETECTED: {len(texts)-1} text elements")
                        results.append(f"  Preview: {text_preview}")
                        logger.info(f"ğŸ“Š Extracted text: {len(full_text)} characters")
                    else:
                        results.append("ğŸ“ TEXT: None detected")
                        logger.info("ğŸ“Š No text detected")
                results.append("")
            except Exception as e:
                error_msg = f"ğŸ“ TEXT: Error - {str(e)}"
                results.append(error_msg)
                logger.error(f"âŒ Text detection exception: {str(e)}")
                results.append("")
        
        # Web Detection
        if 'web' in analysis_features:
            try:
                logger.info("ğŸŒ Performing web detection...")
                response = client.web_detection(image=image)
                logger.info("âœ… Web detection API call completed")
                
                if response.error.message:
                    error_msg = f"ğŸŒ WEB DETECTION: API Error - {response.error.message}"
                    results.append(error_msg)
                    logger.error(f"âŒ Web detection error: {response.error.message}")
                else:
                    web_detection = response.web_detection
                    
                    if web_detection.web_entities:
                        results.append("ğŸŒ WEB ENTITIES:")
                        logger.info(f"ğŸ“Š Found {len(web_detection.web_entities)} web entities")
                        for entity in web_detection.web_entities[:5]:
                            if entity.description:
                                score = int(entity.score * 100) if entity.score else 0
                                results.append(f"  â€¢ {entity.description}: {score}% relevance")
                                logger.debug(f"ğŸŒ Web entity: {entity.description} ({score}%)")
                    
                    if web_detection.best_guess_labels:
                        best_guess = web_detection.best_guess_labels[0].label
                        results.append(f"ğŸ¯ BEST GUESS: {best_guess}")
                        logger.debug(f"ğŸ¯ Best guess: {best_guess}")
                    
                    results.append("")
            except Exception as e:
                error_msg = f"ğŸŒ WEB DETECTION: Error - {str(e)}"
                results.append(error_msg)
                logger.error(f"âŒ Web detection exception: {str(e)}")
                results.append("")
        
        # Safe Search Detection
        if 'safe_search' in analysis_features:
            try:
                logger.info("ğŸ›¡ï¸ Performing safe search detection...")
                response = client.safe_search_detection(image=image)
                logger.info("âœ… Safe search detection API call completed")
                
                if response.error.message:
                    error_msg = f"ğŸ›¡ï¸ SAFE SEARCH: API Error - {response.error.message}"
                    results.append(error_msg)
                    logger.error(f"âŒ Safe search error: {response.error.message}")
                else:
                    safe = response.safe_search_annotation
                    
                    results.append("ğŸ›¡ï¸ SAFE SEARCH:")
                    logger.info("ğŸ“Š Safe search detection successful")
                    safety_attrs = {
                        'Adult': safe.adult.name,
                        'Spoof': safe.spoof.name,
                        'Medical': safe.medical.name,
                        'Violence': safe.violence.name,
                        'Racy': safe.racy.name
                    }
                    for attr, level in safety_attrs.items():
                        if level != 'UNKNOWN':
                            results.append(f"  â€¢ {attr}: {level}")
                            logger.debug(f"ğŸ›¡ï¸ Safety attribute: {attr} ({level})")
                    results.append("")
            except Exception as e:
                error_msg = f"ğŸ›¡ï¸ SAFE SEARCH: Error - {str(e)}"
                results.append(error_msg)
                logger.error(f"âŒ Safe search exception: {str(e)}")
                results.append("")
        
        logger.info("ğŸ‰ Image analysis completed successfully")
        return f"âœ… Vision Image Analysis Complete!\n\n" + "\n".join(results)
        
    except Exception as e:
        error_msg = f"âŒ Error during comprehensive image analysis: {str(e)}"
        logger.error(error_msg)
        return error_msg

@tool
def vision_text_detection_tool(
    image_path: str,
    language_hints: Optional[List[str]] = None,
    uploaded_files: Optional[List[str]] = None
) -> str:
    """
    Extract text from images using Google Cloud Vision API OCR.
    
    This tool uses Cloud Vision's text detection capabilities to extract text
    from images, photos, and scanned documents with high accuracy.
    
    Args:
        image_path: Path to the image file to process
        language_hints: Optional list of language codes to improve recognition
        uploaded_files: List of uploaded file paths from LangGraph state
    
    Returns:
        Extracted text from the image
    """
    try:
        logger.info("ğŸ”„ Initializing Google Cloud Vision client...")
        client = init_vision_client()
        logger.info("âœ… Vision client initialized successfully")
    except Exception as e:
        error_msg = f"âŒ Error: Failed to initialize Google Cloud Vision client: {str(e)}"
        logger.error(error_msg)
        return error_msg
    
    try:
        # Resolve file path first
        resolved_path = _resolve_file_path_from_state(image_path, uploaded_files)
        if not resolved_path:
            error_msg = f"âŒ Error: Image file not found: {image_path}"
            logger.error(error_msg)
            return error_msg
        
        logger.info(f"ğŸ“– Reading image file: {resolved_path}")
        # Read the image file
        with open(resolved_path, "rb") as image_file:
            content = image_file.read()
        
        logger.info(f"âœ… Image loaded: {len(content)} bytes")
        
        # Create image object
        image = vision.Image(content=content)
        
        # Configure image context with language hints
        image_context = None
        if language_hints:
            image_context = vision.ImageContext(language_hints=language_hints)
            logger.info(f"ğŸŒ Using language hints: {language_hints}")
        
        logger.info("ğŸ” Making Vision API call for text detection...")
        # Perform text detection
        if image_context:
            response = client.text_detection(image=image, image_context=image_context)
        else:
            response = client.text_detection(image=image)
        
        logger.info("âœ… Vision API call completed")
        
        # Check for errors
        if response.error.message:
            error_msg = f"âŒ Vision API error: {response.error.message}"
            logger.error(error_msg)
            return error_msg
        
        # Extract text annotations
        texts = response.text_annotations
        if not texts:
            warning_msg = f"âš ï¸ No text detected in image: {os.path.basename(resolved_path)}"
            logger.warning(warning_msg)
            return warning_msg
        
        # The first annotation contains the full text
        full_text = texts[0].description
        logger.info(f"ğŸ“ Text extracted successfully: {len(full_text)} characters")
        
        # Count individual text elements
        individual_texts = len(texts) - 1  # Subtract 1 for the full text annotation
        
        filename = os.path.basename(resolved_path)
        file_size = len(content)
        
        result = f"âœ… Vision Text Detection successful!\n" \
               f"ğŸ–¼ï¸ Image: {filename}\n" \
               f"ğŸ“ File size: {file_size:,} bytes\n" \
               f"ğŸŒ Language hints: {language_hints or ['auto-detect']}\n" \
               f"ğŸ”¤ Text elements found: {individual_texts}\n" \
               f"ğŸ“ Extracted text:\n{full_text}"
        
        logger.info("ğŸ‰ Text detection completed successfully")
        return result
        
    except Exception as e:
        error_msg = f"âŒ Error during Vision text detection: {str(e)}"
        logger.error(error_msg)
        return error_msg

@tool
def vision_document_analysis_tool(
    image_path: str,
    analysis_type: str = "full",
    uploaded_files: Optional[List[str]] = None
) -> str:
    """
    Perform comprehensive document analysis using Google Cloud Vision API.
    
    This tool provides detailed document structure analysis including
    text blocks, paragraphs, words, and symbols with confidence scores.
    
    Args:
        image_path: Path to the image file to analyze
        analysis_type: Type of analysis ('full', 'blocks', 'words', 'symbols')
        uploaded_files: List of uploaded file paths from LangGraph state
    
    Returns:
        Detailed document analysis results
    """
    logger.info(f"ğŸ“„ Starting document analysis for: {image_path} (type: {analysis_type})")
    
    try:
        logger.info("ğŸ”„ Initializing Google Cloud Vision client for document analysis...")
        client = init_vision_client()
        logger.info("âœ… Vision client ready for document analysis")
    except Exception as e:
        error_msg = f"âŒ Error: Failed to initialize Google Cloud Vision client: {str(e)}"
        logger.error(error_msg)
        return error_msg
    
    try:
        # Resolve file path first
        resolved_path = _resolve_file_path_from_state(image_path, uploaded_files)
        if not resolved_path:
            error_msg = f"âŒ Error: Image file not found: {image_path}"
            logger.error(error_msg)
            return error_msg
        
        logger.info(f"ğŸ“– Reading document image: {resolved_path}")
        # Read the image file
        with open(resolved_path, "rb") as image_file:
            content = image_file.read()
        
        logger.info(f"âœ… Document loaded: {len(content):,} bytes")
        
        # Create image object
        image = vision.Image(content=content)
        
        logger.info("ğŸ” Performing document text detection...")
        # Perform document text detection (more detailed than basic text detection)
        response = client.document_text_detection(image=image)
        logger.info("âœ… Document text detection API call completed")
        
        # Check for errors
        if response.error.message:
            error_msg = f"âŒ Vision API error: {response.error.message}"
            logger.error(error_msg)
            return error_msg
        
        # Get the full text annotation
        document = response.full_text_annotation
        if not document.text:
            warning_msg = f"âš ï¸ No text detected in document: {os.path.basename(resolved_path)}"
            logger.warning(warning_msg)
            return warning_msg
        
        logger.info(f"ğŸ“Š Document text extracted: {len(document.text)} characters")
        
        results = []
        filename = os.path.basename(resolved_path)
        
        # Basic information
        results.append(f"ğŸ“„ Document: {filename}")
        results.append(f"ğŸ“ Full text length: {len(document.text)} characters")
        
        # Analyze pages
        if analysis_type in ['full', 'blocks']:
            page_count = len(document.pages)
            results.append(f"ğŸ“„ Pages: {page_count}")
            
            for page_idx, page in enumerate(document.pages):
                block_count = len(page.blocks)
                results.append(f"ğŸ“„ Page {page_idx + 1}: {block_count} text blocks")
                
                if analysis_type == 'full':
                    # Detailed block analysis
                    for block_idx, block in enumerate(page.blocks[:3]):  # Limit to first 3 blocks
                        paragraph_count = len(block.paragraphs)
                        results.append(f"  ğŸ“¦ Block {block_idx + 1}: {paragraph_count} paragraphs")
        
        # Word-level analysis
        if analysis_type in ['full', 'words']:
            total_words = 0
            avg_confidence = 0
            confidences = []
            
            for page in document.pages:
                for block in page.blocks:
                    for paragraph in block.paragraphs:
                        for word in paragraph.words:
                            total_words += 1
                            confidences.append(word.confidence)
            
            if confidences:
                avg_confidence = sum(confidences) / len(confidences)
                results.append(f"ğŸ”¤ Total words: {total_words}")
                results.append(f"ğŸ¯ Average confidence: {avg_confidence:.2f}")
        
        # Symbol-level analysis
        if analysis_type in ['full', 'symbols']:
            total_symbols = 0
            for page in document.pages:
                for block in page.blocks:
                    for paragraph in block.paragraphs:
                        for word in paragraph.words:
                            total_symbols += len(word.symbols)
            
            results.append(f"ğŸ”£ Total symbols: {total_symbols}")
        
        # Add a preview of the text
        text_preview = document.text[:200] + "..." if len(document.text) > 200 else document.text
        results.append(f"ğŸ“– Text preview: {text_preview}")
        
        logger.info("ğŸ‰ Document analysis completed successfully")
        return f"âœ… Vision Document Analysis successful!\n" + "\n".join(results)
        
    except Exception as e:
        error_msg = f"âŒ Error during Vision document analysis: {str(e)}"
        logger.error(error_msg)
        return error_msg 